\documentclass[sigconf]{acmart}
\setcopyright{rightsretained}

\usepackage{listings}
\usepackage{dirtree}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{url}
\usepackage[utf8]{inputenc}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{float}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage[scientific-notation=true]{siunitx}

\usepackage{amssymb}
\usepackage{tabulary}

\usepackage{etoolbox}

\usepackage{algorithm}
\usepackage{algorithmic}

\makeatletter
\newcommand\fs@norules{\def\@fs@cfont{\bfseries}\let\@fs@capt\floatc@ruled
  \def\@fs@pre{}%
  \def\@fs@post{}%
  \def\@fs@mid{\kern3pt}%
  \let\@fs@iftopcapt\iftrue}
\makeatother
\floatstyle{norules}
\restylefloat{algorithm}

\let\tinymatrix\smallmatrix
\let\endtinymatrix\endsmallmatrix
\patchcmd{\tinymatrix}{\scriptstyle}{\scriptscriptstyle}{}{}
\patchcmd{\tinymatrix}{\scriptstyle}{\scriptscriptstyle}{}{}
\patchcmd{\tinymatrix}{\vcenter}{\vtop}{}{}
\patchcmd{\tinymatrix}{\bgroup}{\bgroup\scriptsize}{}{}

\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}

\usepackage[draft,index]{fixme}
\fxsetup{theme=color,mode=multiuser,layout=inline,draft}

% correct bad hyphenation here
%\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{Online (Bandit) Policy Selection for EASY-Backfilling}

\author{Eric Gaussier}
\affiliation{%
  \institution{Univ. Grenoble Alpes, CNRS, Grenoble INP, LIG}
  \country{France}}
\email{eric.gaussier@imag.fr}
\author{J\'er\^ome Lelong}
\affiliation{%
  \institution{Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK}
  \country{France}}
\email{jerome.lelong@imag.fr}
\author{Valentin Reis}
\affiliation{%
  \institution{Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LIG}
  \country{France}}
\email{valentin.reis@imag.fr}
\author{Denis Trystram}
\affiliation{%
  \institution{Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LIG}
  \country{France}}
\email{denis.trystram@imag.fr}

\begin{abstract}

  The EASY-FCFS heuristic is the basic building block of job scheduling
  policies in most parallel High Performance Computing (HPC) platforms. Despite
  its good properties (simplicity, no starvation), it could still be improved
  on a per-system basis. This tuning process is difficult because of
  non-linearities in the scheduling process. The study proposed here considers
  an online approach to the automatic tuning of the EASY heuristic for HPC
  platforms. More precisely, we consider the problem of selecting a reordering
  policy of the job queue under several feedback modes. We show via a
  comprehensive experimental campaign that noisy feedback (using a weak
  simulator) recovers existing in-hindsight results that allow to divide the
  average waiting time up to a factor of 2. Moreover, we show that bandit
  feedback can be used by a simple multi-armed bandit algorithm to decrease the
  average waiting time down to 40\% of its original value without using a
  simulator.

\end{abstract}

\maketitle


\section{Introduction}
\label{sec:intro}

\subsection{Context}

Providing the computing infrastuctures needed to solve actual complex
problems arising in the various fields of the modern society (including
climate change, health, green energy or security) is a strategic challenge.
The main pillar to address this challenge is to build extreme-scale
parallel and distributed platforms.
The race for always more computing power and storage capacity does not
only lead to sophisticated specific exascale platforms, but the
objective of the community is to design efficient sustained Petascale
platforms.
However, there is still a long way to go and many scientific and
technical problems to solve by the system management software in order
to adapt to such large-scale evolution and the increasing complexity
in both architecture and applications.
The existing job and resource management softwares allow to run tens
thousands jobs on hundreds thousands cores.
They are based on robust policies, however, despite their positive
properties of relative simplicity and their guarantee of no job starvation,
there is still place for improvements.
We propose here to study how to tune the classical EASY-BackFilling
heuristic using two new learning approaches (namely, .

\bigskip
The management generates a huge amount of data.
During the last few years, there was an explosion of the number of works
at the interface of HPC and BigData, dealing with learning algorithms
(including the authors of this work~\cite{learningruntimes}).
Most of these studies target the process of determining more or less
accurately the value of some specific key parameters, with the idea that
learning better estimates should improve the performances of the
resource manager.

\bigskip
Our focus within this work is to learn how the management system behaves
within the usual framework of selecting jobs of the submission queue
under EASY-BF.
Contrarily to most existing studies, which consider only one execution
trace, we extend the learning on a multiple traces basis.
We built a simulator which generates a huge number of partial executions
coming from multiple users collected in various actual traces and HPC
platforms.
The sampling is explained in detail later in the paper.
This was motivated because learning for a specific trace/platform leads
to limited results, customized for one particular instance (then, what
happens if we target another platform?).
The collected data are too small and moreover, this approach is usually
inefficient to deal with extreme unpredictable events.
The sampling generation allow to smooth the data.

%On se place du point de vue de l'admin system...

\subsection{Contributions}

Our main contribution is to investigate a new way for learning, which
consists in using of a simulator to generate a large data set extracted
from various actual traces.
We propose two variants of the approach: the ideal situation which
relies on the  precise knowledge of data, and the more realistic
assumption of noisy data (which better reflect the uncertainties).
We also propose a new on-line approach based on multi-armed Bandit to
learn very fast how to prioritize the submission and BackFilling queues.
\bigskip

Our main results are:

l'approche basee sur le simulateur marche bien. meme avec des donnes
imprecises.

Le bandit a des resultats raisonnables, il ne necessite que peu de code
supplementaire...

Dans les details :
on montre que une gestion aleatoire des queues est meilleure que FCFS,
et on identifie des politiques qui marchent bien dans plusieurs traces,
etc..


\section{Related Works}
\label{sec:rw}

This section presents and discuss the most significant results related
to job scheduling and learning algorithms in this context.
Let us start by recalling some basics about scheduling heuristics in HPC
platforms:

While parallel job scheduling is a old studied theoretical
problem~\cite{leung2004handbook} \textbf{PREFER DROZDOWSKI HERE + SURVEY
FEITELSON-RUDOLPH-SWIEGELSHON}, the practical ramifications, varying
hypotheses, and inherent uncertainty of the problem applied on the HPC
field have driven
practitioners to use \textit{simple} heuristics (and researchers to
study their behavior).
The two most popular heuristics for HPC platforms are EASY~\cite{easy} and
Conservative~\cite{Mu'alem:2001:UPW:380314.380315} backfillings.

While Conservative Backfilling offers many advantages~\cite{bfchar}, it
has a
significant computational overhead, which mainly explains why most of
the machines
of the top500 ranking~\cite{top500} rather use a variant of EASY-BF
instead.
There is a large body of work seeking to improve/tune EASY. Indeed,
while the
basic mechanism is used by some actual resource and job management
softwares (most notably
SLURM~\cite{SLURMdocSCHED}), this is rarely done without fine tunings by
system
administrators.

The original EASY mechanism refers to a First-Come-First-Serve basis.
Several works explore how to tune EASY by reordering waiting
and/or backfilling queues~\cite{Tsafrir_easypp_2005}, sometimes even in a
randomized manner~\cite{1592720}, as well as some
implementations~\cite{Jackson2001}. However, as successful as they may
be, these works
do not address the dependency of scheduling metrics on the
workload~\cite{variability}. Indeed these studies most often report
\textit{post-hoc} performance since
they compare algorithms after the workload is known.

The dynP scheduler~\cite{streit_selftuning_2002} proposes a systematic
method to tuning these queues, although it requires simulated scheduling
runs
at decision time and therefore, it costs much more than the natural
execution of EASY.

\paragraph
\textbf{Data-aware resource management.}

There was a recent focus on leveraging the huge amount of data available in
large scale computing systems in order to improve their behavior. Some works
use collaborative filtering to colocate tasks in clouds by estimating
application interference~\cite{7516031}.  Some others are closer to the
application level and use binary classification to distinguish benign memory
faults from application errors in order to execute recovery algorithms
(see~\cite{fmodeling} for instance).

Several works use \textbf{this method} (LAQUELLE?) in the context of HPC, in
particular~\cite{Tsafrir_easypp_2005,learningruntimes}, hoping that
better job
runtime estimations should improve the scheduling~\cite{chiang_impact_2002}.
Some algorithms estimate runtime distributions model and choose jobs using
probabilistic integration procedures~\cite{Nissimov2008}.
However, these works do not address the duality between the cumulative and
maximal scheduling costs, as mentioned in~\cite{learningruntimes}.
While these previous works intend to estimate uncertain parameters, we
consider here a more
pragmatic approach, which directly learn a good scheduling policy from a
given policy space.

\paragraph
\textbf{Multi-Armed Bandits.}

A multi-armed bandit (MAB) problem is a sequential allocation problem with
partially observable rewards. At every round, an action (represented by
an arm of the Bandit) must be chosen
in a fixed set and the corresponding reward is observed. The goal of a MAB
algorithm is to maximize the total reward obtained in a successive
number of rounds.
There exist a bunch of works that address this problem under a variety of
constraints, The two most popular settings are the original stochastic  case
and the adversarial case. See~\cite{thompson} for the original work on the
stochastic case and~\cite{Auer2002} for the UCB family of algorithms
\textbf{EXPLAIN HERE THE ACRONYM}.
According to our knowledge, the work
of~\cite{Banos} is the earliest known work to us for the adversarial case
see~\cite{nonstoch} for the EXP family of algorithms. We refer to the
review~\cite{bubnow} for a comprehensive overview of the field. While these
algorithms bound the cumulative difference in loss to the best arm (the
regret), they have functional constraints such as the fact that the rewards
should be contained in a range. The heuristic called
\textit{Epsilon-Greedy} introduced in~\cite{Auer2002} is known to
achieve good results in practice, and does not have
this requirement.


\section{Problem setting}
\label{sec:problem_setting}

This section presents the systems under study and the scheduling problem.  It
first introduces the EASY-Backfilling heuristic and gives
\textcolor{orange}{(fix ugly sentence)} the problem statement.

\subsection{System Description}
\label{sub:sysdesc}

The problem addressed in this work is the core logic of Resource and Job
Management Systems (RJMS) such as SLURM~\cite{SLURMdocSCHED}, PBS~\cite{PBSdoc},
OAR~\cite{capit2005batch}, Cobalt~\cite{Cobalt}, and more recently Flux~\cite{flux2014}.

The crucial part of batch scheduling software is the scheduling algorithm that determines
where and when the submitted jobs are executed. The process is as follows: jobs
are submitted by end-users and queued until the scheduler selects one of them
for running. Each job has a provided bound on the execution time and some
resource requirements (number and type of processing units). Then, the RJMS
drives the search for the resources required to execute this job. Finally, the
tasks of the job are assigned to the chosen nodes.

In the classical case, these softwares need to execute a set of concurrent
parallel jobs with rigid (known and fixed) resource requirements on a HPC
platform represented by a pool of $m$ identical resources. This is an on-line
problem since the jobs are submitted over time and their characteristics are only known when they are released.
Below is the description and the notations of the characteriscs of job $j$:

\begin{itemize}
  \item Submission date $r_j$ (also called \textit{release date})

  \item Resource requirement $q_j$ (number of processors)

  \item Actual running time $p_j$ (sometimes called \textit{processing time})

  \item Requested running time $\widetilde{p_j}$ (sometimes called \textit{walltime}), which is an upper bound of $p_j$.

\end{itemize}

The resource requirement $q_j$ of job $j$ is known when the job is submitted at
time $r_j$, while the requested running time $\widetilde{p_j}$ is given by the
user as an estimate. Its actual value $p_j$ is only known \textit{a posteriori}
when the job really completes.  Moreover, the users have incentive to
over-estimate the actual values, since jobs may be ``killed'' if they
surpass the provided value.
\subsection{EASY Backfilling}
\label{sub:easy}

The selection of the job to run is performed according to a
scheduling policy that establishes the order in which the jobs are executed.
EASY-Backfilling is the most widely used policy due to its simple and robust
implementation and known benefits such as high system
utilization~\cite{easy}. This strategy has no worst case guarantee beyond
the absence of starvation (i.e. every job will be scheduled at some moment).

The EASY-FCFS heuristic uses a job queue to select and backfill jobs.  At any
time that requires a scheduling decision (i.e. job submission or termination),
the scheduler goes through the job queue in First-Come,First-Serve (FCFS) order
and starts jobs until it finds a job that can not be started right away. It
then makes a reservation for this job at the earliest predictable time and
starts \textit{backfilling} the job queue in FCFS order, starting any job that
does not delay the unique reservation.

\subsection{Scheduling Objective}
\label{sub:scheduling_objectives}

A system administrator may use one or multiple cost metric(s). Our study of
scheduling performance relies on the waiting times of the jobs, which is one of
the more commonly used objectives.

    \begin{equation}
      \textbf{Wait}_j =  start_j-r_j
    \end{equation}

Like other cost metrics, the waiting time is usually considered in its
\textit{cumulative} version, which means that one seeks to minimize the average
waiting time (\textbf{AvgWait}). It is worth noting that the \textbf{MaxWait},
a.k.a the maximal value of the waiting time of all the jobs is also worthy of
interest. Unfortunately, these criteria can sometimes be dual in practice,
making the problem bi-objective. Subsection~\ref{sub:th} will outline our
approach to managing this aspect.

\subsection{Problem Statement}

Our problem statement is: \textbf{How to tune EASY-Backfilling in an online manner?}
\textcolor{orange}{introduce the difference in workloads, the duality of avg and max, and the online problem}

\section{Tuning EASY by reordering and thresholding the job queue}
\label{sec:framework}

This section presents two mechanisms for safely tuning the EASY-Backfilling:
job queue reordering and job thresholding. Together, these two building blocks
constitute a robust framework for tuning EASY.

\subsection{Reordering the job Queue}
\label{subsec:policies}

The EASY heuristic uses a job queue to select and backfill jobs. While this job
queue is ordered in FCFS order in the original heuristic, it is possible to
reorder it at will. We settle on a reasonable search space of 10 reordering policies.

%wait mwait lpf spf sqf lqf expfact mexpfact lrf srf laf saf
\begin{enumerate}
  \item FCFS: First-Come First-Serve, which is the widely used default policy~\cite{easy}.
  \item LCFS: Last-Come First-Serve.
  \item SPF: Smallest estimated Processing time $\widetilde{p_{j}}$ First ~\cite{bfchar}.
  \item LPF: Longest estimated Processing time First.
  \item LQF: Largest resource requirement $q_j$ First.
  \item SQF: Smallest resource requirement First.
  \item LEXP: Largest Expansion Factor First~\cite{bfchar}, where the expansion
    factor is defined as follows:
  \begin{equation} \frac{start_j - r_j + \widetilde{p_j}}{\widetilde{p_j}} \end{equation}
  where $start_j$ is the starting time of job $j$.
  \item SEXP: Smallest Expansion Factor First
  \item LRF: Largest Ratio $\frac{p_j}{q_j}$ First
  \item SRF: Smallest Ratio First
  \item LAF: Largest Area $ p_j \times q_j$ First
  \item SAF: Smallest Area First
\end{enumerate}

This search space is designed with the goal of being as semantically diverse as
possible without making any judgement on which policy should perform well in
practice. In the following, we denote these policies by $P_i$ with $i = 1
\ldots 10$.

\subsection{Thresholding}
\label{sub:th}
As existing works point out, reordering the job queue means losing the
no-starvation guarantee and some individual jobs therefore can wait an undue
amount of time. It is possible to introduce a thresholding mechanism in order
to prevent this behavior: When a job's \textit{waiting time so far} exceeds a
fixed threshold $\Theta$, it is jumped at the head of the queue. We denote by
EASY($P,\Theta$) the scheduling policy that starts and backfill jobs according to
the (thresholded) reordering policy $P$. For the sake of completeness,
Algorithm~\ref{alg:EASY} describes the EASY($P,\Theta$) heuristic.

\begin{algorithm}[h]
  \caption{EASY($P,\Theta$) policy}
  \begin{algorithmic}[1]
    \renewcommand{\algorithmicrequire}{\textbf{Input:}}
    \renewcommand{\algorithmicensure}{\textbf{Output:}}
    \REQUIRE Queue $Q$ of waiting jobs.
    \ENSURE None (calls to $Start()$)
    \STATE Sort $Q$ according to $P_R$
    \STATE Move all jobs of $Q$ for which $wait_j > \Theta$ ahead
    of the queue (breaking ties in FCFS order).
    \\ \textit{Starting jobs until the machine is full}
    \FOR {job $j$ in Q do}
    \IF {$j$ can be started given the current system use.}
    \STATE Pop $j$ from Q
    \STATE $Start(j)$
    \ELSE
    \STATE Reserve $j$ at the earliest
    time possible according to the estimated running times
    of the currently running jobs.
    \\ \textit{Backfilling jobs}
    \FOR {job $j'$ in $Q\setminus\{j\}$}
    \IF {$j'$ can be started without delaying the reservation on $j$.}
    \STATE Pop $j'$ from $Q$
    \STATE $Start(j')$
    \ENDIF
    \ENDFOR
    \STATE \textbf{break}
    \ENDIF
    \ENDFOR
  \end{algorithmic}
  \label{alg:EASY}
\end{algorithm}

\section{Online tuning}
\label{sec:online}

We present here the strategies we have retained for selecting a policy. In the remainder, we will refer to the period during which a selected policy is applied as the \textit{policy period} and will denote the length of this period as $\Delta$. The time interval is thus divided into periods of equal length: $\Delta_0, \cdots, \Delta_T$, where $T$ is the index of the current policy period; all periods have length $\Delta$. At the beginning of each period, from the first period $\Delta_0$ to the current period $\Delta_T$, a new policy is selected.

We assume here that there is a certain regularity among periods, \textit{i.e.} that the distributions underlying the jobs submitted do not radically differ between consecutive periods. This assumption is validated in the study presented in~\ref{???}. It further entails that the behavior of a policy on the previous periods reflects its behavior on the current one, so that the selection of a policy can be based on its behavior on previous periods. However, there usually is an important variability on the cost metric between different periods, for any policy. This is illustrated in Figure~\ref{fig:variability} where \textcolor{orange}{???}. When the cost metric is averaged over different periods, there is a tradeoff to find in between longer periods that would somehow limit the variability, and shorter ones that yield more values for the estimation.

The selection of a policy is of course reminiscent of reinforcement learning. It is important to note, however, that a pure reinforcement learning approach is difficult to develop in our context as \textcolor{orange}{???}. We rely here on simpler, yet we believe more effective, strategies to solve this problem. These strategies are applied online and rely on exact simulation, noisy simulation and $\epsilon$-greedy bandit exploration.

\subsection{Online policy selection with exact simulation}
\label{sub:feedback}

Several simulators have been developed for "playing" reordering policies on a given set of jobs. Such simulations are interesting inasmuch as they provide an estimate of the cost of a given policy on a set of jobs. \textcolor{orange}{TO BE COMPLETED}

Let $l(\Delta_t)$ denote the number of jobs \textit{submitted} during the period $\Delta_t$ ($0 \le t < T$), and $P_i$ ($1 \le i \le 10$) one reordering policy (defined in Section~\ref{subsec:policies}). The cost of policy $P_i$ during the period $\Delta_t$ is defined as:
%
\begin{equation}
\label{eq:cost-exact}
w_{\mbox{exact}}(t;P_i) = \sum_{j=1}^{l(\Delta_t)} \mbox{Wait}_j^{P_i}
\end{equation}
%
where $\mbox{Wait}_j^{P_i}$ denotes the estimate provided by the simulator of the waiting time for job $j$ according to policy $P_i$. The estimation of the cost of a policy over all the periods preceding the current period can then be defined as:
%
\begin{equation}
\label{eq:tot-cost-exact}
w(\rightarrow T;P_i) = \sum_{t=0}^{T-1} \lambda^{T-1-t} w_{\mbox{exact}}(t;P_i)
\end{equation}
%
$\lambda \in [0,1]$ is a decay parameter that can be used to privilege recent history (\textit{i.e.} recent periods). Note that the above cost directly corresponds to the cumulative waiting time of the policy over the preceding periods (more precisely to the cumulative simulated estimate of the waiting time of the policy over the preceding periods) so that the length of the period has no impact here.

In the context of this study, as detailed in Section~\ref{sec:experiments}, we rely on metrics averaged over several execution traces in order to obtain reliable estimate of the behavior of different policies and policy selection strategies. Such traces are typically obtained by simulation. Using the same simulator for generating the traces and estimating the cost as defined in Eqs \ref{eq:cost-exact} and \ref{eq:tot-cost-exact} would however be too optimistic and would represent an upper bound on what can be achieved by a selection strategy based on simulation.

In order to have a more realistic estimate of the behavior of a selection strategy based on simulation, we introduce noise in the simulator, as described below.

\subsection{Online policy selection with noisy simulation}
\label{sub:noisy}

In order to simulate how the simulation strategy for selecting policies would work on non simulated traces, we randomly introduce noise in the estimate of the waiting time defined by Eq.~\ref{eq:cost-exact} by rescaling, either dow or up, the waiting time of jobs obtained by simulation:
%
\begin{equation}
\label{eq:cost-noisy}
w_{\mbox{noisy}}(t;P_i) = \sum_{j=1}^{l(\Delta_t)} \rho \mbox{Wait}_j^{P_i}
\end{equation}
%

\subsection{Bandit policy selection}
\label{sub:bandit}
When we have only bandit feedback of the accurate simulator.
We use the epsilon-greedy bandit\ref{alg:epsg}.

\begin{algorithm}[h]
  \caption{Epsilon-Greedy Bandit policy}
  \begin{algorithmic}[1]
    \renewcommand{\algorithmicrequire}{\textbf{Input:}}
    \renewcommand{\algorithmicensure}{\textbf{Output:}}
    \REQUIRE $0 < \epsilon < 1$, $K>1$
    \FOR {$t = 1, 2, \ldots$}
    \STATE Let $i_t$ be the reordering heuristic with the highest current
    average reward.
    \STATE With probability $1-\epsilon$ use $i_t$ and with probability
    $\epsilon$ use a random reordering heuristic.
    \ENDFOR
  \end{algorithmic}
  \label{alg:epsg}
\end{algorithm}



\section{Experiments}
\label{sec:experiments}

This section compares the different approaches to policy selection via a
comprehensive experimental campaign.  Subsection~\ref{sub:protocol} outlines
the experimental protocol used and Subsection~\ref{sub:results} contains the
experimental results and their discussion.

\subsection{Experimental Protocol}
\label{sub:protocol}

The Evaluation of computer systems performance is an intricate
task\cite{feitbook}. Here, the two main difficulties are choosing a simulation
model and taking into account the variability in the average waiting times.
This section presents our approach and provides a replicable workflow
for the interested reader.

\subsubsection{Traces}
\label{sub:traces}

\begin{table}[ht]
  \centering
  \ra{1.3}
  \caption{Workload logs used in the simulations.}
  \label{tab:logs}
  \begin{tabular}{@{}lrrrr@{}}
    \hline
    Name          & Year & \# MaxProcs & \# Jobs & Duration\\
    \hline
    KTH-SP2       & 1996 & 100         & 28k     & 11 Months\\
    CTC-SP2       & 1996 & 338         & 77k     & 11 Months\\
    SDSC-SP2      & 2000 & 128         & 59k     & 24 Months\\
    SDSC-BLUE     & 2003 & 1,152       & 243k    & 32 Months\\
    ANL-Intrepid  & 2009 & 163840      & 68k     & 9  Months\\
    CEA-Curie     & 2012 & 80,640      & 312k    & 3  Months\\
    Unilu-Gaia    & 2014 & 2,004        & 51k     & 4  Months\\
    \hline
  \end{tabular}
\end{table}

The experimental campaign used in this work uses a mixture of small and large
systems from different periods. Table~\ref{tab:logs} presents the 7 logs, which
can all be obtained from the Parallel Workload
Archive~\cite{Feitelson20142967}. We use the 'cleaned'\footnote{\lstinline[basicstyle=\ttfamily\color{blue}]|http://www.cs.huji.ac.il/labs/parallel/workload/logs.html#clean|} version of the logs as
per the archive. We impose an additional
filtering step to the workloads\footnote{This filtering step is available in
the reproducible workflow\cite{repro} as shell script
\lstinline[basicstyle=\ttfamily\color{blue}]|misc/strong\_filter|} in order to
clean singular data. More precisely, we apply the following modifications:

\begin{enumerate}
  \item If the number of allocated or requested cores of a job  exceeds the size of the machine, we remove the job.
  \item If the number of allocated or requested cores is negative, we use the available positive value as the request. If both are negative, we remove the job.
  \item If the runtime or submission time is negative, we remove the job.
\end{enumerate}

\subsubsection{Simulator}

The choice of a simulator is a critical part of experimental validation that
raises a tradeoff between precision and runtime. High precision can be obtained
by carefully modeling the platform and its network topology, or extracting
information from the jobs from their sources or post-morted logs. This is the
approach used by high-fidelity batch scheduling simulators such as
Batsim~\cite{batsim}. In the present work, the focus is on studying the
EASY-Backfilling mechanism in itself, without adressing the allocation problem.
Moreover, the experimental protocol used here requires many simulation runs.
Therefore, we set the precision/runtime tradeoff at the point which minimizes
simulation runtimes. We discard all topological information relative to the
platform and use the job processing times of the original workloads. In this
setup, the processors are considered to be undistinguishable from each other,
and jobs can be discontinuously mapped to any available processor on the
system. We develop a lightweight simulator\cite{ocst} and an accompanying
multi-armed bandit library\cite{obandit}. See the reproducibility paragraph
below for more information.  With this simulator, we are able to replay
EASY-FCFS on the CEA-CURIE trace in 33 seconds with a machine equipped with an
Intel(R) Core(TM) i5-4310U CPU @ 2.00GHz. As a point of comparison, the Batsim
simulator with no network communication modeling and no resource contiguity
takes more than 7 hours to replay the same trace on the same hardware. The complete
simulation campaign presented below is executed on a single Dell PowerEdge R730 in 22
hours, including input preparation and analysis code.

\subsubsection{Resampling}
\label{ssub:resampling}

\begin{figure*}[ht]
  \centering
  \includegraphics[scale=0.6]{figures/variability.pdf}
  \caption{Variability in the weekly average waiting time in the KTH-SP2 trace (pre-processing described in subsection~\ref{sub:traces}) for a few policies.}
  \label{fig:mosn}
\end{figure*}

%Validating algorithms on real data is a notoriously hard
%problem~\cite{feitbook}. The case of batch scheduling is made especially
%difficult by the fluctuations in commonly used metrics~\cite{jsm}. Indeed, the
%variability in performance is known to outrank the available sample sizes:
%\textit{It is not enough to simply replay an algorithm using a trace}. For this
%reason, we clearly expose our statistical approach.

%Two main methods are available in order to generate data. On one hand, it is
%possible to model~\cite{feitperfeval} workloads. However, this often loses
%many specificities of the original data, and this work uses a second
%approach based on trace resampling~\cite{feitresampling}.

To carry our experiments, we need to generate many trace samples. More precisely, we want
to sample the job submission process, which is achieved by splitting the traces in weeks,
randomly shuffling them and picking the jobs submitted in the selected weeks.  This simple
mechanism enables us to preserve the dependency within a week. Although the system state
may not be independent from one week to an other, we can reasonably assume that it evolves
under its stationary distribution. Thus, computing an average over the sampled traces at a
given time can be related to a time average of an underlying Markov process, which
converges to the true quantity thanks to the ergodic theorem.  Moreover, the job
submission process has no long range correlation making it look like an independent and
identically distributed process when considering sufficiently time spaced weeks.

\subsubsection{Experimental campaign}


\subsubsection{Replicability}

Readers interested in replicating the experiments (or a part thereof) are
invited to peruse to the 'artifacts description' appendix of this paper.  We
provide to persistent archives containing the simulator, the analysis code
and an automated workflow that replicates all experiments and figures
present in this paper.

\subsection{Results}
\label{sub:results}

\begin{figure*}[h]
  \centering
  \includegraphics[scale=0.6]{figures/CTC-SP2.pdf}
  \includegraphics[scale=0.6]{figures/KTH-SP2.pdf}\\
  \includegraphics[scale=0.6]{figures/CEA-Curi.pdf}
  \includegraphics[scale=0.6]{figures/SDSC-BLU.pdf}\\
  \includegraphics[scale=0.6]{figures/SDSC-SP2.pdf}
  \includegraphics[scale=0.6]{figures/ANL-Intr.pdf}

  \caption{Evolution of the average cumulative waiting time improvement
    compared to EASY-FCFS of the FullFeedback, NoisyFeedback and EpsilonGreedy
    policies. The average is obtained by resampling the original trace 100
    times. The dashed lines represent the 10th and 90th percentiles of the
  values across this resampling. Each figure is a different trace, and this
figure is followed-up in figure~\ref{fig:follow} for the UniLu-Gaia log.}

  \label{fig:small}
\end{figure*}

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.6]{figures/UniLu-Ga.pdf}

  \caption{Follow-up from figure~\ref{fig:small}, plot for the UniLu-Gaia log.}

  \label{fig:follow}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.6]{figures/full-UniLu-Ga.pdf}

  \caption{Evolution of the average cumulative waiting time improvement
    compared to EASY-FCFS of the policies $P_i$ for $i = 1 \ldots 10$ on the
    UniLu-Gaia trace. The
    average is obtained by resampling the original trace 100 times. The dashed
    lines represent the 10th and 90th percentiles of the values across this
  resampling.}

  \label{fig:all}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.6]{figures/mosaicbandit-UniLu-Ga.pdf}
  \caption{Share of the policies chosen by Epsilon-Greedy as a function of time.
  The average choice is obtained by resampling the original trace 100 times and
  aggregating by date.}
  \label{fig:mosb}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.6]{figures/mosaic-UniLu-Ga.pdf}
  \caption{Share of the policies chosen by the Noisy policy. The average
  choice is obtained by resampling the original trace 100 times and
  aggregating by date.}
  \label{fig:mosn}
\end{figure}

\section{Conclusion}
\label{sec:ccl}

\begin{acks}

Authors are sorted in alphabetical order. The authors would like to warmly
thank Pierre Neyron for help with computational experiments and Arnaud Legrand
for discussions about reproducibility. We gracefully thank the contributors of
the Parallel Workloads Archive, Victor Hazlewood (SDSC SP2), Travis Earheart
and Nancy Wilkins-Diehr (SDSC Blue), Lars Malinowsky (KTH SP2), Dan Dwyer and
Steve Hotovy (CTC SP2), Joseph Emeras (CEA Curie and UniLu Gaia), Susan
Coghlan, Narayan Desay, Wei Tang (ANL Intrepid), and of course Dror Feitelson.
The Metacentrum workload log was graciously provided by the Czech National Grid
Infrastructure MetaCentrum. This work has been partially supported by the LabEx
PERSYVAL-Lab(\grantsponsor{ANR-11-LABX-0025-01}{ANR-11-LABX-0025-01}) funded by
the French program Investissement d'avenir.
\end{acks}

\bibliographystyle{acmst}
\bibliography{bibliography}

\clearpage

\section{artifact description: [online (bandit) policy selection for easy-backfilling]}

\subsection{Abstract}

This appendix describes the computational artifacts associated with this work. We
take a lightweight approach to replicability by packaging a declarative
workflow that generates all the figures from this paper and making it available
publicly. Moreover, questions regarding replication can be freely directed at
the authors via e-mail.

All the code associated with this work is released under the ~\cite{isc}
license as a persistent zenodo~\cite{zenodo} archive at~\cite{zenodomain}.

\subsection{Description}

There are various approaches for making computational experiments replicable,
among which distributing complete operating system images, containers, or
packaging software. As our experiments are cpu bound, we decide to opt for the
software packaging approach. This allows for replicating the experiments on clusters where virtualization is not
available or kernels are too old for containers old and decreases runtime.

All the dependencies of our
experiments (including our own code, dependencies for data processing and
visualization and workflow engine) are automatically managed by Nix up to the
actual execution of the code.

\subsubsection{Check-list (artifact meta information)}

{\small
\begin{itemize}
  \item {\bf algorithm: Scheduling Simulation Workflow}
  \item {\bf program: Ocaml, R, Bash, Zymake(all sources and dependencies included)}
  \item {\bf compilation: Ocaml 4.02.3, GNU bash version 4.4.5(1)-release, R version 3.3.2}
  \item {\bf transformations: Patched nix standard environment.}
  \item {\bf binary: Most binaries are cached by Nix channels.}
  \item {\bf data set: Traces from the parallel workload archive, included.}
  \item {\bf run-time environment: Nixpkgs 17.03}
  \item {\bf hardware: Dell PowerEdge R730}
  \item {\bf output: Files}
  \item {\bf experiment workflow: \lstinline[basicstyle=\ttfamily\color{blue}]|zymakefile|, see below}
  \item {\bf publicly available?: Yes}
\end{itemize}
}

\subsubsection{Obtaining the code.}

Running the experiments can be done on any platform equipped with the nix
package manager by running:

\begin{lstlisting}
nix-build (fetchTarball ...)
\end{lstlisting}

\subsubsection{Hardware}

 Experiments presented in this paper were carried out using the Grid'5000
 testbed. Grid'5000 is supported by a scientific interest group hosted by Inria
 and including CNRS, RENATER and several Universities as well as other
 organizations\footnote{https://www.grid5000.fr}.  Access to the experimental
 machine(s) used in this paper was gracefully granted by research teams from
 LIG\footnote{http://www.liglab.fr} and Inria\footnote{http://www.inria.fr}.

 The experiments in this paper can run via in less than 24 hours on a
 moderately parallel host. More precisely, we had access to a Dell PowerEdge
 R730 equipped with a total of 56 threads @2.4GHz each and 757G of RAM. For
 this reason, the experimental campaign workflow was designed to be executed on
 a single host.


\subsubsection{Software dependencies}

All the software dependencies of our code
Managed by Nix.

\dirtree{%
.1 root .
.2 zymakefile .
.2 default.nix .
.2 pkgs .
.2 gz .
.3 ANL-Intrepid.swf.gz .
.3 CEA-Curie.swf.gz .
.3 CTC-SP2.swf.gz .
.3 KTH-SP2.swf.gz .
.3 SDSC-BLUE.swf.gz .
.3 SDSC-SP2.swf.gz .
.3 UniLu-Gaia.swf.gz .
.2 misc .
.3 strongvisu .
.3 visu .
.2 ocst .
.2 paper .
}

\subsubsection{Datasets}

From Swf Archive. Cached.

\subsection{Installation}

nix-build

\subsection{Experiment workflow}

 All experiments are tied together using zymake~\cite{zymake}, a minimalistic
 workflow system designed for computational experiments\footnote{the zymake system
 is also packaged by our nix expressions.}. This system is
 analogous to a traditional build system with added workflow capabilities. The
 entire workflow that generates this article from the input data is contained
 in a single \lstinline[basicstyle=\ttfamily\color{blue}]|zymakefile| to be
 found at the root of the main archive. This workflow is composed of the
 following steps:

 \begin{itemize}
   \item[data]: Data extraction from archives, filtering, resampling.
     this is principally using shell scripts for data manipulation (see file
     \lstinline[basicstyle=\ttfamily\color{blue}]|misc/strong\_filter| for the
     filtering steps used) and ocaml code that implements the resampling method
     described in~\ref{ssub:resampling}.

   \item[simulation]: This step runs the lightweight ocaml backfilling
     simulator specially written for this work. this simulator is made
     available under the isc~\cite{isc} license both as a persistent zenodo
     archive at~\cite{ocst} and as a git repository at ~\cite{ocstgit}.

   \item[analysis]: This step runs r code that generates the figures
     presented in this paper.
 \end{itemize}


\subsection{Evaluation and expected result}

o/zymakefile/pdfs

\subsection{Experiment customization}

modify zymakefile

\subsection{Notes}
This artefact description was prepared according to the guidelines located at \url{http://ctuning.org/ae/submission.html}
\end{document}
